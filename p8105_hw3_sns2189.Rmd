---
title: "Homework 3"
author: Safiya Sirota
date: 2021-10-20
output: 
  github_document:
    toc: TRUE
---

```{r, echo = FALSE, message = FALSE}
library(tidyverse)
library(patchwork)
library(p8105.datasets)
  data("instacart")
  data("brfss_smart2010")

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

__Describing the `instacart` dataset:__

`instacart` is a dataset with `r nrow(instacart)` rows and `r ncol(instacart)` columns. Each row represents a single product that was part of an order via Instacart. Some key variables that we use in our exploration below are 

* `product_name` (e.g., "`r pull(instacart, product_name)[1]`", "`r pull(instacart, product_name)[2]`", or `"r pull(instacart, product_name)[3]`"), 

* `aisle` (e.g., "`r pull(instacart, aisle)[1]`", "`r pull(instacart, aisle)[2]`", or "`r pull(instacart, aisle)[3]`"), and

* `order_hour_of_day`, which notes the the hour of day from 0-23 during which the order was placed.

__Counting aisles:__

```{r}
instacart %>% 
  group_by(aisle) %>% 
  summarize(aisle_ct = n()) %>% 
  nrow()
```

There are 134 aisles in the dataset.

__Determining popular aisles:__

```{r}
instacart %>% 
  group_by(aisle) %>% 
  summarize(aisle_ct = n()) %>% 
  arrange(desc(aisle_ct)) %>% 
  top_n(5) %>% 
  knitr::kable()
```

It makes sense to me that fruits and vegetables are ordered often. There are a wide variety of foods in these aisles, they represent important food groups, and fruits and vegetables also go bad quicker than other items which calls for more frequent orders. Packaged cheese is also a common product and can run out quickly. Especially because cheese is a common ingredient for breakfast, lunch, and dinner recipes. I'm a little surprised that yogurt is also on this top 5 list,, but if each small yogurt container counts as 1 item, people may buy many units each time they order, which add up quickly.

__Making a plot showing the number of items ordered in each aisle:___

```{r fig.asp = 1}

instacart %>% 
  group_by(aisle) %>% 
  summarize(aisle_ct = n()) %>% 
  filter(aisle_ct >= 10000) %>% 
  ggplot(aes(x = fct_reorder(aisle, aisle_ct), y = aisle_ct, fill = aisle_ct)) +
  geom_col() +
  coord_flip() +
  scale_y_continuous(
    breaks = c(25000, 50000, 75000, 100000, 125000, 150000)
  ) + 
  labs(
    title = "Instacart orders",
    x = "Aisle",
    y = "Number of products ordered"
  ) +
  theme(legend.position = "none")
```

A couple things that surprise me about this plot are the amount of orders from the water aisle and the lack of orders from the butter aisle. The high volume of water orders show that customers may not favor tap water or water filters. Many may instead enjoy bottled or sparkling water more than I thought. I also thought butter would be ordered more frequently. In a larger household, it seems like a refrigerator staple that could run out quickly. Perhaps butter (and oils and vinegars) last longer and require less reorders.

__Showing the 3 most popular items in 3 aisles:__

```{r}
baking <-
  instacart %>% 
    filter(aisle == "baking ingredients") %>% 
    group_by(product_name) %>% 
    summarize(product_ct = n()) %>% 
    arrange(desc(product_ct)) %>% 
    top_n(3)  %>% 
    mutate(
      aisle = "Baking Ingredients",
      rank = 1:3
    )

dog_food <-
  instacart %>% 
    filter(aisle == "dog food care") %>% 
    group_by(product_name) %>% 
    summarize(product_ct = n()) %>% 
    arrange(desc(product_ct)) %>% 
    top_n(3) %>% 
    mutate(
      aisle = "Dog Food & Care",
      rank = 1:3
    )

pkg_veg_fruit <-
  instacart %>% 
    filter(aisle == "packaged vegetables fruits") %>% 
    group_by(product_name) %>% 
    summarize(product_ct = n()) %>% 
    arrange(desc(product_ct)) %>% 
    top_n(3) %>% 
    mutate(
      aisle = "Packaged Vegetables & Fruits",
      rank = 1:3
    )

full_join(baking, dog_food) %>% 
  full_join(pkg_veg_fruit) %>% 
  select(aisle, rank, product_name, product_ct) %>% 
  knitr::kable()
```

I find it interesting that light brown sugar was ordered more than cane sugar, since I think it's more common for baking recipes to call for cane sugar. Perhaps people already have large quantities of cane sugar at home but prefer to buy smaller packs of brown sugar and reorder when needed. It makes sense to me that the top items from the dog food aisle are treats and foods. I find it interesting that the most frequently ordered packaged vegetable or fruit is a vegetable. Perhaps this shows that spinach is a very popular packaged vegetable, while people may have a wider variety of preferences when it comes to which packaged fruits they like to order.


__Showing the mean hour of  day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week:__

```{r}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  select(product_name, order_dow, order_hour_of_day) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour_of_day = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour_of_day
  ) %>% 
  rename(
      "Sunday" = `0`,
      "Monday" = `1`,
      "Tuesday" = `2`,
      "Wednesday" = `3`,
      "Thursday" = `4`,
      "Friday" = `5`,
      "Saturday" = `6`
      ) %>% 
  knitr::kable(digits = 1)
```

It seems that Coffee Ice Cream is ordered, on average, later in the day on each day of the week besides Friday. The website describing `instacart` finds that "ice cream and frozen pizza are the most frequently ordered products late at night." I think that fact could account for the higher mean of Coffee Ice Cream when compared to Pink Lady Apples.

## Problem 2

__Tidying the data:__

```{r}
brfss_smart2010_tidy <-
brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  filter(
    topic == "Overall Health" & 
    response %in% c("Poor", "Fair", "Good", "Very good", "Excellent")
    ) %>% 
  mutate(
    response = factor(response),
    response = forcats::fct_relevel(
      response, 
      c("Poor", "Fair", "Good", "Very good", "Excellent")
      )
  ) 
```

__Showing which states were observed at 7 or more locations in 2002 and 2010:__

```{r}
brfss_smart2010_tidy %>% 
  filter(year == 2002) %>% 
  select(locationabbr, locationdesc) %>% 
  group_by(locationabbr) %>% 
  summarize(county_ct = n_distinct(locationdesc)) %>% 
  filter(county_ct >= 7) %>% 
  knitr::kable(digits = 0)
  

brfss_smart2010_tidy %>% 
  filter(year == 2010) %>% 
  select(locationabbr, locationdesc) %>% 
  group_by(locationabbr) %>% 
  summarize(county_ct = n_distinct(locationdesc)) %>% 
  filter(county_ct >= 7) %>% 
  knitr::kable(digits = 0)
  
```

We can see that 8 more states are observed at 7 or more locations in 2010. This makes sense because as the years go on, and as there is more funding for research, increasing the sample would be important to the researchers. Also, as more people got their own telephones, it was probably easier to contact more participants in a variety of counties by 2010. The mean number of counties included for each state also increases from 2002 to 2010.

__Constructing a dataset and plot of mean `Excellent` responses in each state:__ 

```{r}
brfss_smart2010_tidy %>% 
  filter(response == "Excellent") %>% 
  group_by(year, locationabbr) %>% 
  summarize(mean_data_value = mean(data_value, na.rm = TRUE)) %>% 
  ggplot(aes(x = year, y = mean_data_value, color = locationabbr)) +
  geom_line() +
  labs(
    title = "Mean proportion of 'Excellent' responses by state",
    x = "Year",
    y = "Mean proportion"
  ) +
  theme(legend.position = "none")
```

From this plot, it seems that there isn't much of a general trend across states in terms of whether the number of "Excellent" responses go up and down. Instead we can look at specific lines towards the top or bottom of the plot to see which states are at the extremes. For example, the yellow line at the bottom represents West Virginia, while the purple line that contains the highest data point in 2004 is Washington, D.C.

__Plotting distribution of responses in NY for 2006 and 2010:__

```{r}
plot_2006 <-
  brfss_smart2010_tidy %>% 
  filter(year == 2006 & locationabbr == "NY") %>% 
  group_by(response) %>% 
  summarize(response_mean = mean(data_value)) %>% 
  ggplot(aes(x = response, y = response_mean)) +
  geom_col() + 
  labs(
    title = "NY Distribution 2006",
    x = "Response",
    y = "Mean proportion of responses"
  ) + 
  theme(axis.text.x = element_text(angle = 90)) +
  ylim(c(0,35))


plot_2010 <-
  brfss_smart2010_tidy %>% 
  filter(year == 2010 & locationabbr == "NY") %>% 
  group_by(response) %>% 
  summarize(response_mean = mean(data_value)) %>% 
  ggplot(aes(x = response, y = response_mean)) +
  geom_col() + 
  labs(
    title = "NY Distribution 2010",
    x = "Response",
    y = "Mean proportion of responses"
  ) + 
  theme(axis.text.x = element_text(angle = 90)) +
  ylim(c(0,35))

plot_2006 + plot_2010 
```

These plots actually don't look extremely different, but we can see clearly that there were a larger proportion of "Very good" responses in 2010 when compared to 2006 in NY state. However, there are slightly more "Poor" responses too. It seems like people in 2010 were less likely to feel more neutral about their health with "Fair" and "Good" responses, and favored the slightly more extreme responses of "Poor" or "Very Good" when compared to respondents in 2006.

## Problem 3

__Tidying the data:__

```{r}
accel_df <- read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    weekday_vs_weekend = case_when(
      day %in% c("Saturday", "Sunday") ~ "weekend",
      TRUE ~ "weekday")
  )
```

`accel_df` is a dataset with `r nrow(accel_df)` rows and `r ncol(accel_df)` columns. Each row represents a single day, and columns show observations at each minute of the day, starting at midnight. Therefore the key variables that we use are

* `day_id`(values from 1-35 that mark the day),

* `day` (day of the week, i.e., "Monday", "Tuesday", etc.),

* `activity_*`(where * represents the minute of the day, ranging from 1-1440, and the value is the acitvity level at that minute), and

* `weekday_vs_weekend` (whether the day of the week is during the weekday or on the weekend)


__Create a table showing total activity per day__:

```{r}
accel_df %>% 
  rowwise(day_id) %>% 
  mutate(activity_total = sum(c_across(activity_1:activity_1440))) %>% 
  select(day_id, day, weekday_vs_weekend, activity_total) %>% 
  knitr::kable(digits = 1)

```

I find it a bit difficult to notice any trends from just looking at the table. We can quickly plot this table to observe trends.

```{r}
accel_df %>% 
  rowwise(day_id) %>% 
  mutate(activity_total = sum(c_across(activity_1:activity_1440))) %>% 
  select(day_id, day, weekday_vs_weekend, activity_total) %>% 
  ggplot(aes(x = day_id, y = activity_total)) +
  geom_line()
```

From this plot, it looks like activity level fluctuates from day to day. A lower-energy day is often followed by a higher-energy day and vice-versa. It's also important to notice that on days 24 and 31, there is only 1 "activity count" per minute, leading to a sum of 1440. These data are probably not reliable and may be missing.


__Plotting the 24-hour activity time courses for each day:__

```{r}
accel_df %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute",
    names_prefix = "activity_",
    values_to = "activity"
  ) %>% 
  mutate(minute = as.numeric(minute)) %>% 
  ggplot(aes(x = minute, y = activity, group = day_id, color = day)) +
  geom_line(alpha = .8) +
  scale_x_continuous(
    breaks = c(1, 360, 720, 1080, 1440),
    labels = c("12am", "6am", "12pm", "6pm", "12am")
  ) + labs(
    title = "Activity plot",
    x = "Hour of day",
    y = "Activity level"
  )
```

We can tell from this plot that activity levels are low in the early morning hours, which makes sense because the subject is probably sleeping and not very active. It looks like the subject may wake up around 6am and fall asleep around 10pm in general. There are often activity peaks around 10-1pm, from 4-6pm, and from 8-10pm. It seems like Wednesdays may be lower energy days for the subject in general. Also, Fridays seem like higher energy days. It may be easier to pick out more specific trends if we focus on a subset of days, or if we split the graph into multiple panels.
